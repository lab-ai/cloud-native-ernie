# Propoasal
## Docker
å¸¸ç”¨æŒ‡ä»¤

1. æŸ¥çœ‹æœ¬åœ°é•œåƒ ```docker images```
2. åˆ›å»ºå®¹å™¨ ```docker run -dit --name=å®¹å™¨å é•œåƒid /bin/bash ```
3. æŸ¥çœ‹æ‰€æœ‰çš„å®¹å™¨ ```docker ps -a```
4. å¯åŠ¨å®¹å™¨ï¼ˆä¹‹å‰ä»¥åˆ›å»ºè¿‡çš„å®¹å™¨ï¼‰ ```docker start å®¹å™¨å```
5. è¿›å…¥å®¹å™¨ ```docker exec -it å®¹å™¨å /bin/bashÂ·```
6. é€€å‡ºå®¹å™¨ ```exit```
7. å°†å®¹å™¨åˆ¶ä½œæˆé•œåƒ ```docker  commit  -m  'é•œåƒæè¿°'  -a  'åˆ¶ä½œè€…'  å®¹å™¨å  é•œåƒå```
8. å°†åˆ¶ä½œå¥½çš„é•œåƒæ‰“æˆ tar åŒ… ```docker  save  -o  taråŒ…çš„åå­—  é•œåƒå```
9. æ ¹æ®Dockerfileåˆ›å»ºå®¹å™¨ ```docker build -t nginx:v1 .```
10. æœ¬åœ°ä¸Šä¼ æ–‡ä»¶ ```docker inspect -f '{{.ID}}' å®¹å™¨å``` ```docker cp æœ¬åœ°è·¯å¾„ å®¹å™¨é•¿ID:å®¹å™¨è·¯å¾„```

[å‚è€ƒé“¾æ¥1](https://www.cnblogs.com/pjcd-32718195/p/11762079.html)
[å‚è€ƒé“¾æ¥2](https://www.cnblogs.com/ityouknow/p/8588725.html)
[å‚è€ƒé“¾æ¥3](https://blog.csdn.net/xbw12138/article/details/79126396)

## Ernie
###NLP ä»»åŠ¡çš„è§£å†³è¿‡ç¨‹

1. åŸºäºtokenization.pyè„šæœ¬ä¸­çš„Tokenizerå¯¹è¾“å…¥çš„å¥å­è¿›è¡ŒtokenåŒ–ï¼Œå³æŒ‰å­—ç²’åº¦å¯¹å¥å­è¿›è¡Œåˆ‡åˆ†ï¼›
2. åˆ†ç±»æ ‡å¿—ç¬¦å·[CLS]ä¸tokenåŒ–åçš„å¥å­æ‹¼æ¥åœ¨ä¸€èµ·ä½œä¸ºERNIEæ¨¡å‹çš„è¾“å…¥ï¼Œç»è¿‡ ERNIE å‰å‘è®¡ç®—åå¾—åˆ°æ¯ä¸ªtokenå¯¹åº”çš„embeddingå‘é‡è¡¨ç¤ºï¼›
3. åœ¨å•å¥åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œ[CLS]ä½ç½®å¯¹åº”çš„åµŒå…¥å¼å‘é‡ä¼šç”¨æ¥ä½œä¸ºåˆ†ç±»ç‰¹å¾ã€‚åªéœ€å°†[CLS]å¯¹åº”çš„embeddingæŠ½å–å‡ºæ¥ï¼Œå†ç»è¿‡ä¸€ä¸ªå…¨è¿æ¥å±‚å¾—åˆ°åˆ†ç±»çš„ logits å€¼ï¼Œæœ€åç»è¿‡softmaxå½’ä¸€åŒ–åä¸è®­ç»ƒæ•°æ®ä¸­çš„labelä¸€èµ·è®¡ç®—äº¤å‰ç†µï¼Œå°±å¾—åˆ°äº†ä¼˜åŒ–çš„æŸå¤±å‡½æ•°ï¼›
4. ç»è¿‡å‡ è½®çš„fine-tuningï¼Œå°±å¯ä»¥è®­ç»ƒå‡ºè§£å†³å…·ä½“ä»»åŠ¡çš„ERNIEæ¨¡å‹ã€‚

[simple-caseä»£ç åŠç®€æ˜“æ•™ç¨‹](https://aistudio.baidu.com/aistudio/projectdetail/874233)



###è¿è¡Œé™¤ernie-with-jinaçš„dockerfileå¤–æ‰€éœ€é¢å¤–ç¯å¢ƒï¼š

```pip install vim```

```pip install wget```

```pip install sklearn```

```wget https://ernie-github.cdn.bcebos.com/data-chnsenticorp.tar.gz```

```tar xvf data-chnsenticorp.tar.gz```

è¿è¡Œç¤ºä¾‹ç¨‹åºä¼šä¸‹è½½ ```https://ernie-github.cdn.bcebos.com/model-ernie1.0.1.tar.gz```ã€‚ è‹¥ä¸‹è½½å¤±è´¥ï¼Œæ‰‹åŠ¨ ```wget https://ernie-github.cdn.bcebos.com/model-ernie1.0.1.tar.gz``` éšåè§£å‹å¹¶ç§»è‡³ç›®æ ‡ç›®å½•ã€‚

## BERTï¼ˆBidirectional Encoder Representations from Transformersï¼‰

### natural language processing tasks:

1. sentence-level tasks such as natural language inference and paraphrasing, which aim to predict the relationships between sentences by analyzing them holistically
2. token-level tasks such as named entity recognition and question answering, where models are required to produce ï¬ne-grained output at the token level

### two existing strategies for applying pre-trained language representations to downstream tasks: 

1. feature-based: such as ELMo, uses task-speciï¬c architectures that include the pre-trained representations as additional features 
2. ï¬ne-tuning: such as the Generative Pre-trained Transformer, introduces minimal task-speciï¬c parameters, and is trained on the downstream tasks by simply ï¬ne-tuning all pretrained parameters

The two approaches share the same objective function during pre-training, where they use unidirectional language models to learn general language representations.

BERT alleviates the previously mentioned unidirectionality constraint by using a â€œmasked language modelâ€ (MLM) pre-training objective, inspired by the Cloze task (Taylor, 1953). The masked language model randomly masks some of the tokens from the input, and the objective is to predict the original vocabulary id of the masked word based only on its context.

There are two steps in BERT framework: pre-training and ï¬ne-tuning. During pre-training, the model is trained on unlabeled data over different pre-training tasks. For ï¬netuning, the BERT model is ï¬rst initialized with the pre-trained parameters, and all of the parameters are ï¬ne-tuned using labeled data from the downstream tasks. Each downstream task has separate ï¬ne-tuned models, even though they are initialized with the same pre-trained parameters.

## X as service

```python
from jina.flow import Flow

f = (Flow(callback_on_body=True)
     .add(name='spit', uses='Sentencizer')
     .add(name='encode', uses='jinaai/hub.executors.encoders.nlp.transformers-pytorch',
          parallel=2, timeout_ready=20000))

```
1. What is transformers

	"Griezmann", "his", "Frenchman" can be pointed as one person in a paragraph. Capturing such relationships and sequence of words in sentences is vital for a machine to understand a natural language. This is where the Transformer concept plays a major role.

	1. Sequence-to-Sequence Models â€“ A Backdrop
		
		convert sequences of Type A to sequences of Type B. For example, translation of English sentences to German sentences is a sequence-to-sequence task.
		
	2. Recurrent Neural Network (RNN) based sequence-to-sequence models
		ï¼ˆ1ï¼‰Both Encoder and Decoder are RNNs
		ï¼ˆ2ï¼‰At every time step in the Encoder, the RNN takes a word vector (xi) from the input sequence and a hidden state (Hi) from the previous time step
		ï¼ˆ3ï¼‰The hidden state is updated at each time step
		ï¼ˆ4ï¼‰The hidden state from the last unit is known as the context vector. This contains information about the input sequence
	
	The Transformer in NLP is a novel architecture that aims to solve sequence-to-sequence tasks while handling long-range dependencies with ease.
	
2. What is ```jinaai/hub.executors.encoders.nlp.transformers-pytorch``` and how to change it.
	
	[url is here](https://www.analyticsvidhya.com/blog/2019/07/pytorch-transformers-nlp-python/?utm_source=blog&utm_medium=7-innovative-machine-learning-github-projects-in-python)

	'I have taken this p from PyTorch-Transformersâ€™ documentation. This library currently contains PyTorch implementations, pre-trained model weights, usage scripts and conversion utilities for the following models:

	BERT (from Google) released with the paper BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding

	GPT (from OpenAI) released with the paper Improving Language Understanding by Generative Pre-Training

	GPT-2 (from OpenAI) released with the paper Language Models are Unsupervised Multitask Learners

	Transformer-XL (from Google/CMU) released with the paper Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context

	XLNet (from Google/CMU) released with the paper XLNet: Generalized Autoregressive Pretraining for Language Understanding

	XLM (from Facebook) released together with the paper Cross-lingual Language Model Pretraining

	All of the above models are the best in class for various NLP tasks. Some of these models are as recent as the previous month!

	Most of the State-of-the-Art models require tons of training data and days of training on expensive GPU hardware which is something only the big technology companies and research labs can afford. But with the launch of PyTorch-Transformers, now anyone can utilize the power of State-of-the-Art models!'
	
## Jina
### Document & Chunk

1. a Document is anything that you want to search for

2. a Chunk is a small semantic unit of a Document

### YAML config 

A YAML config is widely used in Jina to describe the properties of an object.

### Executor

Executor represents an algorithmic unit in Jina.

### Driver

Driver defines how an Executor behaves on network requests.

### Pea

Pea wraps an Executor and grants it the ability to exchange data over a network. 

### Pod

Pod is a group of Peas with the same property. 

### Flow

Flow represents a high-level task,

```python
f = (Flow().add(name='p1')
           .add(name='p2', image='jinaai/hub.executors.encoders.bidaf:latest')
           .add(name='p3'))
```
p2 is running in a container



### Running in a minimum working example

``` mwu.py```:

```python
import numpy as np

 from jina.executors.encoders import BaseEncoder

 class MWUEncoder(BaseEncoder):

     def __init__(self, greetings: str, *args, **kwargs):
         super().__init__(*args, **kwargs)
         self._greetings = greetings

     def encode(self, data, *args, **kwargs):
         self.logger.info('%s %s' % (self._greetings, data))
         return np.random.random([data.shape[0], 3])
```

è¿™é‡Œï¼Œå¦‚æœä½¿ç”¨ç¤ºä¾‹ä»£ç çš„```data:Any``` ä¼šæŠ¥é”™ã€‚

```mwu.yml```:

```
!MWUEncoder
 with:
   greetings: hello there!
 metas:
   name: my-mwu-encoder
   py_modules: mwu.py
   workspace: ./
```

```test.py```:

```python
from jina.flow import Flow

f = (Flow()
    .add(name='dummyEncoder', uses='mwu.yml'))

# test it with dry run
with f:
    f.dry_run()
```

result:

```zsh
dummyEncoder@4874[I]:post initiating, this may take some time...
   dummyEncoder@4874[I]:post initiating, this may take some time takes 0.001 secs
   dummyEncoder@4874[S]:successfully built MWUEncoder from a yaml config
   dummyEncoder@4874[I]:setting up sockets...
   dummyEncoder@4874[I]:input tcp://0.0.0.0:60509 (PULL_BIND) 	 output tcp://0.0.0.0:60510 (PUSH_BIND)	 control over tcp://0.0.0.0:60511 (PAIR_BIND)
   dummyEncoder@4874[S]:ready and listening
           JINA@4872[I]:using <class 'uvloop.Loop'> as event loop
        gateway@4872[S]:gateway is listening at: 0.0.0.0:60516
           Flow@4872[I]:2 Pods (i.e. 2 Peas) are running in this Flow
           Flow@4872[S]:flow is now ready for use, current build_level is 1
           Flow@4872[W]:calling dry_run() on a flow is depreciated, it will be removed in the future version. calling index(), search(), train() will trigger a dry_run()
        gateway@4872[S]:terminated
   dummyEncoder@4874[I]:received "control" from ctlâ–¸âš
   dummyEncoder@4874[I]:RequestLoopEnd() causes the breaking from the event loop
   dummyEncoder@4874[I]:no update since 2020-09-15 11:16:41, will not save. If you really want to save it, call "touch()" before "save()" to force saving
   dummyEncoder@4874[I]:executor says there is nothing to save
   dummyEncoder@4874[I]:#sent: 0 #recv: 1 sent_size: 0 Bytes recv_size: 251 Bytes
   dummyEncoder@4874[I]:#sent: 1 #recv: 1 sent_size: 295 Bytes recv_size: 251 Bytes
   dummyEncoder@4874[S]:terminated
           Flow@4872[S]:flow is closed and all resources should be released already, current build level is 0
```




### è·‘é€šxx-as-serviceçš„example
ä»£ç å¦‚ä¸‹

``` python
from jina.flow import Flow

f = (Flow(callback_on_body=True)
     .add(name='spit', uses='Sentencizer')
     .add(name='encode', uses='enc.yml',
          parallel=2, timeout_ready=20000))
```

```enc.yml```
ä¸º

```
!TransformerTorchEncoder
with:
  pooling_strategy: cls
  model_name: distilbert-base-cased
  max_length: 96
```

```python
def input_fn():
    with open('README.md') as fp:
        for v in fp:
            yield v.encode()
```
```python
def print_embed(req):
    for d in req.docs:
        for c in d.chunks:
            embed = pb2array(c.embedding)
            text = colored(f'{c.text[:10]}...' if len(c.text) > 10 else c.text, 'blue')
            print(f'{text} embed to {embed.shape} [{embed[0]:.3f}, {embed[1]:.3f}...]')
```
```python
with f:
    f.index(input_fn, batch_size=32, callback=print_embed)

```
éœ€å®‰è£…çš„ä¾èµ–æœ‰:

``` pip install transformers```

``` pip install torch torchvision -i https://pypi.tuna.tsinghua.edu.cn/simple``` 

é—®é¢˜

åœ¨dockerä¸Šè¿è¡Œï¼Œä¼šæœ‰ä¸€ä¸‹é—®é¢˜

```
ğŸ³ usage: jina [-h] [-v] [-vf]
ğŸ³ {hello-world, pod, flow, gateway ... 6 more choices} ...
ğŸ³ jina: error: unrecognized arguments: --port-expose 62290
         encode@9412[S]:terminated
         encode@9408[C]:fail to start <class 'jina.peapods.container.ContainerPea'> with name encode, this often means the executor used in the pod is not valid

```

ï¼ˆç–‘ä¼¼ç¼ºå°‘argumentï¼‰

### æµ‹è¯•ç‰ˆæœ¬

python 3.7.8

æ‰€éœ€ä¾èµ–ï¼š

```python3 -m pip install paddlepaddle -i https://mirror.baidu.com/pypi/simple```

```pip install jina```

import numpy as np

 from jina.executors.encoders import BaseEncoder

 class MWUEncoder(BaseEncoder):

```mwu.py```

```python
import numpy as np

from jina.executors.encoders import BaseEncoder

import paddle.fluid as fluid

class MWUEncoder(BaseEncoder):

    def __init__(self, greetings: str, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._greetings = greetings

    def encode(self, data, *args, **kwargs):
        self.logger.info('%s %s' % (self._greetings, data))
        data = np.random.random([data.shape[0], 3])
        add = fluid.layers.elementwise_add(data,data)
        place = fluid.CPUPlace()
        exe = fluid.Executor(place)
        add_result = exe.run(fluid.default_main_program(),
                 fetch_list=[add],
                 return_numpy=True)
        return add_result
```
### æµ‹è¯• Build Bert-based NLP Semantic Search System

åœ¨ä¸€ä¸ªterminalæ‰“å¼€ï¼š

``` docker run -p 45678:45678 jinaai/hub.app.distilbert-southpark:latest```

åœ¨å¦ä¸€ä¸ªterminalæ‰“å¼€ï¼š

```curl --request POST -d '{"top_k": 10, "mode": "search",  "data": ["text:hey, Monica"]}' -H 'Content-Type: application/json' 'http://0.0.0.0:45678/api/search'```

## åŸºäºX-as-serviceè¿›è¡Œæµ‹è¯•

1. å°†dockerä»transformersæ¢æˆpaddlehubã€‚

   1. ``` git clone https://github.com/jina-ai/jina-hub.git```

   2. ```cd encoders/nlp/TextPaddlehubEncoder```

   3. ```docker build -t jina-paddle-encoder:v1 .```

   4. åœ¨app.pyä¸­ï¼Œå°†

      ```python
      f = (Flow(callback_on_body=True)
           .add(name='spit', uses='Sentencizer')
           .add(name='encode', uses='jinaai/hub.executors.encoders.nlp.transformers-pytorch',
                parallel=1, timeout_ready=20000))
      ```

      æ¢æˆ

      ```python
      f = (Flow(callback_on_body=True)
           .add(name='spit', uses='Sentencizer')
           .add(name='encode', uses='jina-paddle-encoder:v1',
                parallel=1, timeout_ready=20000))
      ```

2. è€ƒè™‘ä¿®æ”¹dockerfileï¼ŒåŠ å…¥ernieçš„åŠŸèƒ½